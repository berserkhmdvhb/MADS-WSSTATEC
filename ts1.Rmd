---
title: "Daily Climate Time Series Analysis"
author: "Hamed Vaheb"
#date: "11/4/2022"
output:
    html_document: default
    pdf_document: default
    number_sections: true
    toc: true
    code_folding: "hide"
    theme: readable
    highlight: haddock  
---
# Import Libraries
```{r message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(ggplot2)
library(broom)
library(reshape2)
library(readr)
library(readxl)
#library(Ecdat)
library(janitor)
library(plm)
library(pwt9)
library(quarto)
library(renv)
library(shiny)
library(targets)
library(testthat)
library(tidyverse)
library(tibble)
library(usethis)
library(rio)
library(lubridate)
library(purrr)
library(Hmisc)
library(plotly)
library(hrbrthemes)
library(xts)
#library(zoo)
library(seasonal)
library(tsbox)
library(forecast)
#library(seasonalview)
#library(autoplotly)

library(shades) #edit colours in natural ways:

```

```{r}

colorize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```
```{r}
#webshot::install_phantomjs()
```

# Introduction

## Describe Dataset

The dataset used for this project is [Daily Delhi Climate](https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data), which consists of the following columns:
1. `date`: Date of format YYYY-MM-DD starting from "2013-01-01" and ending in "2017-01-01".
2. `meantemp`: Mean temperature averaged out from multiple 3 hour intervals in a day.
3. `humidity`: Humidity value for the day (units are grams of water vapor per cubic meter volume of air).
4. `wind_speed`: Wind speed measured in kmph.
5. `mean_pressure`: Pressure reading of weather (measure in atm)



## Goal and Procedure
The goal of this project is to analyze and forecast the mean temperature Delhi, which is recorded in the meantemp column.
For this, after importing the dataset, outliers are removed. Then meantemp column

```{r}

df_train <- read_csv("files/DailyDelhiClimateTrain.csv")
```

```{r}
summary(df_train)
```
```{r}
df_train |> describe()
```

# Visualize Data
Below we can see interactive plot of the time series.
```{r}
p <- df_train |>
  ggplot( aes(x=date, y=meantemp)) +
    geom_area(fill="#69b3a2", alpha=0.5) +
    geom_line(color="#69b3a2") +
    ylab("bitcoin price ($)") +
    theme_ipsum()

# Turn it interactive with ggplotly
p <- ggplotly(p)
#p
p

```

# Preprocessing
We can detect an outlier at the last observation (last row of dataframe). It causes an abrupt decrease in value of temperature. This would lead to problems in further analysis I will proceed and also when I later apply functions on the time series. Therefore, I replace the last observation's value with its previous one.

`r colorize("Q1. Is imputing with the last observation the right approach here? Or is preferrable that I use median of last n (rows) for instance? Maybe it won't matter, as when I aggregate data (per week, month, week, etc.), I remove the last observation.", "red")`
```{r}
previous_value <- df_train$meantemp[df_train$date == as.Date('2016-12-31')]

df_train$meantemp[df_train$date == as.Date('2017-01-01')]<- previous_value 
```

```{r}
#df_train <- head(df_train, -1)

```

```{r}
tail(df_train)

```


```{r}
p <- df_train |>
  ggplot( aes(x=date, y=meantemp)) +
    geom_area(fill="#69b3a2", alpha=0.5) +
    geom_line(color="#69b3a2") +
    ylab("bitcoin price ($)") +
    theme_ipsum()

# Turn it interactive with ggplotly
p <- ggplotly(p)
#p
p

```


Find if there is any missing dates
```{r}
date_range <- seq(min(df_train$date), max(df_train$date), by = 1) 
date_range[!date_range %in% df_train$date] 

```
# Time Series Analysis
## Construct Time Series 

Now we use the ```meantemp``` column to create our time series data.
I assigned the time series to xts objects. But since many functions later require ts object, each time I define an xts, I also convert it to ts object using ```tsbox::ts_ts``` 


```{r}
min(df_train$date)
max(df_train$date)
```

```{r}
#ts_train <- zoo(df_train$meantemp, df_train$date)

xts_train <- xts(df_train$meantemp, order.by=df_train$date, "%Y-%m-%d")
class(xts_train)
head(xts_train)
tail(xts_train)

# convert xts to ts

## Create a daily Date object for ts
#inds <- seq(as.Date("2013-01-01"), as.Date("2017-01-01"), by = "day")

#set.seed(25)
#ts_train <- ts(df_train$meantemp,     # random data
#           start = c(2013, as.numeric(format(inds[1], "%j"))),
#           frequency = 365)


#ts_train <- ts(df_train$meantemp, start = decimal_date(ymd("2013-01-01")), frequency = 365.25 / 7)

ts_train <-ts_ts(xts_train)
head(ts_train)
tail(ts_train)
```
## Seasonality 


From the initial plot I judge that there is yearly seasonality. 
For more delicate observation to find if there is more granular periods of seasonality, I use seasonality plots.
Before that, I aggregate data weekly, monthly, and quarterly.

### Seasonality Plots
```{r}
# Weekly mean temperature
xts_week_train <- apply.weekly(xts_train,sum)
ts_week_train <-ts_ts(xts_week_train)

# Monthly mean temperature
xts_mon_train <- aggregate(xts_train, by=as.yearmon, FUN=sum)
ts_mon_train <-ts_ts(xts_mon_train)

# Quarterly mean temperature
xts_quar_train <- aggregate(xts_train, as.yearqtr, FUN=sum)
ts_quar_train <-ts_ts(xts_quar_train)


# Yearly mean temperate
as.year <- function(x) as.integer(as.yearmon(x))
xts_year_train <- aggregate(xts_train, by=as.year, FUN=sum)
#ts_year_train <-ts_ts(xts_year_train)
#xts_year_train[1]

```


The year 2017 has only one observation, so I remove it from all the aggregated datasets. I couldn't do it before aggregating, otherwise I would have confronted the error ```Error: series has no regular pattern```.

```{r}

xts_week_train <- head(xts_week_train, -1)
xts_mon_train <- head(xts_mon_train, -1)
xts_quar_train <- head(xts_quar_train, -1)

ts_week_train <- head(ts_week_train, -1)
ts_mon_train <- head(ts_mon_train, -1)
ts_quar_train <- head(ts_quar_train, -1)


```


```{r}
#options(repr.plot.width = 7, repr.plot.height =20)
forecast::ggseasonplot(ts_mon_train, year.labels=TRUE, year.labels.left=TRUE, labelgap = 0.1) +
  ylab("degree") +
  ggtitle("Seasonal plot: Monthly Mean Temperature")
```
```{r}
forecast::ggseasonplot(ts_mon_train, year.labels=TRUE, year.labels.left=TRUE, labelgap = 0.1, polar=TRUE) +
  ylab("degree") +
  ggtitle("Seasonal plot: Monthly Mean Temperature")
```



```{r}
#options(repr.plot.width = 7, repr.plot.height =20)
forecast::ggseasonplot(ts_quar_train, year.labels=TRUE, year.labels.left=TRUE, labelgap = 0.1) +
  ylab("degree") +
  ggtitle("Seasonal plot: Monthly Mean Temperature")
```







```{r}
forecast::ggseasonplot(ts_quar_train, year.labels=TRUE, year.labels.left=TRUE, labelgap = 0.1, polar=TRUE) +
  ylab("degree") +
  ggtitle("Seasonal plot: Monthly Mean Temperature")
```
### Deseasonalize

If I need to remove different periods of seasonality together, I would need to use the ```forecast:msts``` function.
For instance in below I remove weekly and yearly seasonality together.
```{r}
des_ts_train <- msts(xts_train,seasonal.periods = c(7,365))
#head(des_xts_train)
#library(tsbox)
#ts_train <-ts_ts(xts_train)
#ts_train

class(des_ts_train)

```
However, since its output had an unfamiliar and weird shape to me, and also since I wasn't sure it uses the state-of-the-art X13 decomposition, I incorporated the [X-13ARIMA-SEATS](http://www.seasonal.website/seasonal.html) using ```seasonal:seas``` function.
However, it has some limitations, as stated in the package's [reference manua](https://www2.census.gov/software/x-13arima-seats/x-13-data/documentation/docx13as.pdf).
For instance, the number of observations must not exceed 780. Nor should maximum seasonal period exceed 12.
That is why I couldn't use original data ```ts_train``` and also the weekly aggregated data ```ts_week_train```, as I would confront the error ```Seasonal period too large```. The only possible aggregated data with highest frequency possible was monthly aggregated, ```ts_mon_train```.
However, I am concerned that I would lose significant pattern and information with this amount of aggregation.
`r colorize("Q2. If you could kindly share your viewpoint here, it would be very helpful for me to ensure how to proceed.", "red")`

```{r}
length(xts_train)
length(ts_train)

length(xts_train)
nowXTS <-ts_xts(ts_train)
length(nowXTS)

length(ts_week_train)
```
```{r}
plot(ts_train)
length(ts_train)

```


```{r}
plot(ts_mon_train)
length(ts_mon_train)
```


```{r}
m <- seas(ts_mon_train)
m
```

Plot original data along with trend and seasonally adjusted data

```{r}
#ts_train
#series(m, "forecast.forecasts")
#out(m)
#seasadj(m)
autoplot(ts_mon_train, series="Original Data") +
autolayer(trendcycle(m), series="Trend") +
autolayer(seasadj(m), series="Seasonally Adjusted") +
xlab("Year") + ylab("Mean Temperature") +
ggtitle("Mean Temperature Decomposed using X13") +
scale_colour_manual(values=c("gray","blue","red"),
           breaks=c("Original Data","Seasonally Adjusted","Trend"))
#ap < ggplotly(ap)

```


```{r}
m <- seas(ts_mon_train)
ts_train_adj <- final(m)
#ts_train_adj
length(ts_train_adj)
```


```{r}
plot(ts_train_adj)
```

## Detrend
In the seasonally adjusted time series ```ts_train_adj```, I detected a trend, therefore I detrend it using differencing.
```{r}
ts_train_adj <- diff(ts_train_adj)
plot(ts_train_adj)
```
## Unit Root Test
```{r}

```
